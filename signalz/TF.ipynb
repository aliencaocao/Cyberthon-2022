{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_25596\\152761604.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['feature 0'] = X['feature 0'].apply(clean_date)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col=0, header=0)\n",
    "df_test = pd.read_csv('test.csv', index_col=0, header=0)\n",
    "\n",
    "def clean_date(x):\n",
    "    return x.replace('-','')\n",
    "\n",
    "features = ['feature 0', 'feature 1', 'feature 2', 'feature 3', 'feature 4', 'feature 5', 'feature 6', 'feature 7', 'feature 9']\n",
    "\n",
    "X = df_train[features]\n",
    "X['feature 0'] = X['feature 0'].apply(clean_date)\n",
    "Y = df_train['predict']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                640       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,025\n",
      "Trainable params: 9,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xIn = Input(shape=(len(features),))\n",
    "x = Dense(64, activation='swish')(xIn)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='swish')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='swish')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "xOut = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=xIn, outputs=xOut)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 4s 38ms/step - loss: 1281715732480.0000 - mse: 1281715732480.0000 - val_loss: 186944224.0000 - val_mse: 186944224.0000\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 375896408064.0000 - mse: 375896408064.0000 - val_loss: 532702592.0000 - val_mse: 532702592.0000\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183340924928.0000 - mse: 183340924928.0000 - val_loss: 4460686848.0000 - val_mse: 4460686848.0000\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 105124216832.0000 - mse: 105124216832.0000 - val_loss: 599835712.0000 - val_mse: 599835712.0000\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 80851902464.0000 - mse: 80851902464.0000 - val_loss: 1251420288.0000 - val_mse: 1251420288.0000\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 56705085440.0000 - mse: 56705085440.0000 - val_loss: 8383637.5000 - val_mse: 8383637.5000\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 43683631104.0000 - mse: 43683631104.0000 - val_loss: 33147746.0000 - val_mse: 33147746.0000\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37192855552.0000 - mse: 37192855552.0000 - val_loss: 163902768.0000 - val_mse: 163902768.0000\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31206035456.0000 - mse: 31206035456.0000 - val_loss: 1275623552.0000 - val_mse: 1275623552.0000\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21715277824.0000 - mse: 21715277824.0000 - val_loss: 167059888.0000 - val_mse: 167059888.0000\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 16693198848.0000 - mse: 16693198848.0000 - val_loss: 36329452.0000 - val_mse: 36329452.0000\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 15669218304.0000 - mse: 15669218304.0000 - val_loss: 15154836.0000 - val_mse: 15154836.0000\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 16117484544.0000 - mse: 16117484544.0000 - val_loss: 6274082.5000 - val_mse: 6274082.5000\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 10652623872.0000 - mse: 10652623872.0000 - val_loss: 42290420.0000 - val_mse: 42290420.0000\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9983953920.0000 - mse: 9983953920.0000 - val_loss: 171174240.0000 - val_mse: 171174240.0000\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8054298624.0000 - mse: 8054298624.0000 - val_loss: 38061848.0000 - val_mse: 38061848.0000\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5839490048.0000 - mse: 5839490048.0000 - val_loss: 44315876.0000 - val_mse: 44315876.0000\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5313792000.0000 - mse: 5313792000.0000 - val_loss: 24331930.0000 - val_mse: 24331930.0000\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5639424512.0000 - mse: 5639424512.0000 - val_loss: 8855997.0000 - val_mse: 8855997.0000\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4994357248.0000 - mse: 4994357248.0000 - val_loss: 925687.1250 - val_mse: 925687.1250\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2922859776.0000 - mse: 2922859776.0000 - val_loss: 4778641.5000 - val_mse: 4778641.5000\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3358483712.0000 - mse: 3358483712.0000 - val_loss: 3739254.5000 - val_mse: 3739254.5000\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3908525568.0000 - mse: 3908525568.0000 - val_loss: 3009513.7500 - val_mse: 3009513.7500\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2992190976.0000 - mse: 2992190976.0000 - val_loss: 10980093.0000 - val_mse: 10980093.0000\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2963262720.0000 - mse: 2963262720.0000 - val_loss: 5182132.5000 - val_mse: 5182132.5000\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2702531328.0000 - mse: 2702531328.0000 - val_loss: 5525393.0000 - val_mse: 5525393.0000\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2155237632.0000 - mse: 2155237632.0000 - val_loss: 5326810.5000 - val_mse: 5326810.5000\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1930634368.0000 - mse: 1930634368.0000 - val_loss: 3460798.7500 - val_mse: 3460798.7500\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2005288192.0000 - mse: 2005288192.0000 - val_loss: 3432947.0000 - val_mse: 3432947.0000\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1993366272.0000 - mse: 1993366272.0000 - val_loss: 2531823.7500 - val_mse: 2531823.7500\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1948320512.0000 - mse: 1948320512.0000 - val_loss: 3395578.7500 - val_mse: 3395578.7500\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2244920576.0000 - mse: 2244920576.0000 - val_loss: 432989.0000 - val_mse: 432989.0000\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1410245120.0000 - mse: 1410245120.0000 - val_loss: 1120609.6250 - val_mse: 1120609.6250\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1884392320.0000 - mse: 1884392320.0000 - val_loss: 280.1011 - val_mse: 280.1011\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1206601472.0000 - mse: 1206601472.0000 - val_loss: 872771.8125 - val_mse: 872771.8125\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2149084160.0000 - mse: 2149084160.0000 - val_loss: 1190703.0000 - val_mse: 1190703.0000\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1340973440.0000 - mse: 1340973440.0000 - val_loss: 1553707.6250 - val_mse: 1553707.6250\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1290699648.0000 - mse: 1290699648.0000 - val_loss: 2458206.5000 - val_mse: 2458206.5000\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1274112256.0000 - mse: 1274112256.0000 - val_loss: 1111545.2500 - val_mse: 1111545.2500\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1063448576.0000 - mse: 1063448576.0000 - val_loss: 194818.5156 - val_mse: 194818.5156\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 783130368.0000 - mse: 783130368.0000 - val_loss: 270264.1562 - val_mse: 270264.1562\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1210310784.0000 - mse: 1210310784.0000 - val_loss: 205300.8125 - val_mse: 205300.8125\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 945368320.0000 - mse: 945368320.0000 - val_loss: 164701.0156 - val_mse: 164701.0156\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 760525120.0000 - mse: 760525120.0000 - val_loss: 459119.2500 - val_mse: 459119.2500\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 694684608.0000 - mse: 694684608.0000 - val_loss: 809829.2500 - val_mse: 809829.2500\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1259155712.0000 - mse: 1259155712.0000 - val_loss: 286195.8750 - val_mse: 286195.8750\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 744733440.0000 - mse: 744733440.0000 - val_loss: 308115.6875 - val_mse: 308115.6875\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 602514496.0000 - mse: 602514496.0000 - val_loss: 1705.1499 - val_mse: 1705.1499\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 754396544.0000 - mse: 754396544.0000 - val_loss: 75888.2422 - val_mse: 75888.2422\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 585203072.0000 - mse: 585203072.0000 - val_loss: 67.9484 - val_mse: 67.9484\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 857116032.0000 - mse: 857116032.0000 - val_loss: 24667.0508 - val_mse: 24667.0508\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 701523648.0000 - mse: 701523648.0000 - val_loss: 17965.7754 - val_mse: 17965.7754\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 429588384.0000 - mse: 429588384.0000 - val_loss: 347688.0938 - val_mse: 347688.0938\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 548440320.0000 - mse: 548440320.0000 - val_loss: 51887.2109 - val_mse: 51887.2109\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 714446848.0000 - mse: 714446848.0000 - val_loss: 8585.2520 - val_mse: 8585.2510\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 363089088.0000 - mse: 363089088.0000 - val_loss: 316919.6875 - val_mse: 316919.6875\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 268533088.0000 - mse: 268533088.0000 - val_loss: 43623.3672 - val_mse: 43623.3672\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 384930432.0000 - mse: 384930432.0000 - val_loss: 71623.5938 - val_mse: 71623.5938\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 451284960.0000 - mse: 451284960.0000 - val_loss: 14434.4658 - val_mse: 14434.4658\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 460063008.0000 - mse: 460063008.0000 - val_loss: 99252.1250 - val_mse: 99252.1250\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 473483424.0000 - mse: 473483424.0000 - val_loss: 25591.8164 - val_mse: 25591.8164\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 345677280.0000 - mse: 345677280.0000 - val_loss: 772298.0000 - val_mse: 772298.0000\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 341616352.0000 - mse: 341616352.0000 - val_loss: 50671.4180 - val_mse: 50671.4180\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 458402272.0000 - mse: 458402272.0000 - val_loss: 68637.2344 - val_mse: 68637.2344\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 381814464.0000 - mse: 381814464.0000 - val_loss: 35629.9102 - val_mse: 35629.9102\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 257333072.0000 - mse: 257333072.0000 - val_loss: 2224.7190 - val_mse: 2224.7190\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 798716096.0000 - mse: 798716096.0000 - val_loss: 30900.3750 - val_mse: 30900.3750\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 404420896.0000 - mse: 404420896.0000 - val_loss: 138270.9219 - val_mse: 138270.9219\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 355128640.0000 - mse: 355128640.0000 - val_loss: 7716.8169 - val_mse: 7716.8169\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 429565920.0000 - mse: 429565920.0000 - val_loss: 290531.9688 - val_mse: 290531.9688\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 420799840.0000 - mse: 420799840.0000 - val_loss: 101188.1562 - val_mse: 101188.1562\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181046304.0000 - mse: 181046304.0000 - val_loss: 137665.4531 - val_mse: 137665.4531\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 284563456.0000 - mse: 284563456.0000 - val_loss: 224028.8125 - val_mse: 224028.8125\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 401296448.0000 - mse: 401296448.0000 - val_loss: 200332.3594 - val_mse: 200332.3594\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199012672.0000 - mse: 199012672.0000 - val_loss: 1546.7791 - val_mse: 1546.7791\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179294160.0000 - mse: 179294160.0000 - val_loss: 2759.7358 - val_mse: 2759.7358\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 286346624.0000 - mse: 286346624.0000 - val_loss: 190907.2969 - val_mse: 190907.2969\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 299998976.0000 - mse: 299998976.0000 - val_loss: 16617.9473 - val_mse: 16617.9473\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191742000.0000 - mse: 191742000.0000 - val_loss: 168028.3906 - val_mse: 168028.3906\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 325600704.0000 - mse: 325600704.0000 - val_loss: 1054.7407 - val_mse: 1054.7407\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 102251480.0000 - mse: 102251480.0000 - val_loss: 68480.5156 - val_mse: 68480.5156\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110820160.0000 - mse: 110820160.0000 - val_loss: 46770.6289 - val_mse: 46770.6289\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126206776.0000 - mse: 126206776.0000 - val_loss: 26848.2207 - val_mse: 26848.2207\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145907792.0000 - mse: 145907792.0000 - val_loss: 147223.3438 - val_mse: 147223.3438\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143536928.0000 - mse: 143536928.0000 - val_loss: 27238.4844 - val_mse: 27238.4844\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192847856.0000 - mse: 192847856.0000 - val_loss: 162683.1094 - val_mse: 162683.1094\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187978832.0000 - mse: 187978832.0000 - val_loss: 15028.6309 - val_mse: 15028.6309\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 276053696.0000 - mse: 276053696.0000 - val_loss: 17537.7988 - val_mse: 17537.7988\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114401304.0000 - mse: 114401304.0000 - val_loss: 83522.5000 - val_mse: 83522.5000\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 98104368.0000 - mse: 98104368.0000 - val_loss: 3075.7993 - val_mse: 3075.7993\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 95835048.0000 - mse: 95835048.0000 - val_loss: 42725.8359 - val_mse: 42725.8359\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155031120.0000 - mse: 155031120.0000 - val_loss: 137017.0469 - val_mse: 137017.0469\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115401752.0000 - mse: 115401752.0000 - val_loss: 17864.9688 - val_mse: 17864.9688\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156798768.0000 - mse: 156798768.0000 - val_loss: 1537.1145 - val_mse: 1537.1145\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 59531236.0000 - mse: 59531236.0000 - val_loss: 1452.2985 - val_mse: 1452.2985\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 286428000.0000 - mse: 286428000.0000 - val_loss: 38670.7500 - val_mse: 38670.7500\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163743296.0000 - mse: 163743296.0000 - val_loss: 11079.2139 - val_mse: 11079.2139\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 47210152.0000 - mse: 47210152.0000 - val_loss: 4075.0598 - val_mse: 4075.0598\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 60562256.0000 - mse: 60562256.0000 - val_loss: 294.0531 - val_mse: 294.0531\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 59686692.0000 - mse: 59686692.0000 - val_loss: 8309.9082 - val_mse: 8309.9082\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x13465afbeb0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.asarray(X).astype(np.float32), np.asarray(Y).astype(np.float32), epochs=100, batch_size=32, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}