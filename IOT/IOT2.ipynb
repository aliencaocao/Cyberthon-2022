{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "Xtest = []\n",
    "for i in os.listdir('Files'):\n",
    "    try:\n",
    "        with open('Files/'+i, 'r', encoding='utf-8') as f:\n",
    "            xml = f.read().replace('\\n', ' ')\n",
    "        convo = re.search('<convo>(.*)</convo>', xml).group(1)\n",
    "        cls = re.search('<class>(.*)</class>', xml).group(1)\n",
    "        if cls:\n",
    "            X.append(convo)\n",
    "            Y.append(cls)\n",
    "        else:\n",
    "            Xtest.append(convo)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(i)\n",
    "        print(e)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X = pd.Series(X)\n",
    "Y = pd.Series(Y)\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000).fit(X)\n",
    "# Fit and transform/vectorize the training set\n",
    "vec_x = vectorizer.transform(X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True).fit(vec_x)\n",
    "vec_x = tfidf_transformer.transform(vec_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "\n",
    "# Initialize our machine learning model\n",
    "#model = linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=100, tol=None, n_jobs=-1)\n",
    "model = ensemble.HistGradientBoostingClassifier(max_iter=1000, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.371 GB of training data: 1.348 s\n",
      "Binning 0.041 GB of validation data: 0.020 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.64436, val loss: 0.64543, in 0.123s\n",
      "[2/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.61695, val loss: 0.61899, in 0.143s\n",
      "[3/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.59408, val loss: 0.59723, in 0.145s\n",
      "[4/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.57513, val loss: 0.57920, in 0.148s\n",
      "[5/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.55858, val loss: 0.56319, in 0.138s\n",
      "[6/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.54500, val loss: 0.55029, in 0.146s\n",
      "[7/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.53364, val loss: 0.53948, in 0.150s\n",
      "[8/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.52283, val loss: 0.52946, in 0.141s\n",
      "[9/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.51460, val loss: 0.52188, in 0.139s\n",
      "[10/1000] 1 tree, 31 leaves, max depth = 25, train loss: 0.50639, val loss: 0.51403, in 0.135s\n",
      "[11/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.49936, val loss: 0.50740, in 0.145s\n",
      "[12/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.49364, val loss: 0.50219, in 0.146s\n",
      "[13/1000] 1 tree, 31 leaves, max depth = 19, train loss: 0.48774, val loss: 0.49705, in 0.143s\n",
      "[14/1000] 1 tree, 31 leaves, max depth = 24, train loss: 0.48284, val loss: 0.49272, in 0.135s\n",
      "[15/1000] 1 tree, 31 leaves, max depth = 20, train loss: 0.47841, val loss: 0.48866, in 0.131s\n",
      "[16/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.47460, val loss: 0.48492, in 0.137s\n",
      "[17/1000] 1 tree, 31 leaves, max depth = 24, train loss: 0.47113, val loss: 0.48181, in 0.136s\n",
      "[18/1000] 1 tree, 31 leaves, max depth = 20, train loss: 0.46810, val loss: 0.47911, in 0.142s\n",
      "[19/1000] 1 tree, 31 leaves, max depth = 19, train loss: 0.46533, val loss: 0.47676, in 0.144s\n",
      "[20/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.46279, val loss: 0.47457, in 0.138s\n",
      "[21/1000] 1 tree, 31 leaves, max depth = 25, train loss: 0.46058, val loss: 0.47276, in 0.132s\n",
      "[22/1000] 1 tree, 31 leaves, max depth = 22, train loss: 0.45857, val loss: 0.47125, in 0.136s\n",
      "[23/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.45685, val loss: 0.47021, in 0.221s\n",
      "[24/1000] 1 tree, 31 leaves, max depth = 26, train loss: 0.45513, val loss: 0.46897, in 0.176s\n",
      "[25/1000] 1 tree, 31 leaves, max depth = 25, train loss: 0.45363, val loss: 0.46795, in 0.160s\n",
      "[26/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.45222, val loss: 0.46706, in 0.164s\n",
      "[27/1000] 1 tree, 31 leaves, max depth = 23, train loss: 0.45077, val loss: 0.46605, in 0.154s\n",
      "[28/1000] 1 tree, 31 leaves, max depth = 20, train loss: 0.44952, val loss: 0.46525, in 0.150s\n",
      "[29/1000] 1 tree, 31 leaves, max depth = 23, train loss: 0.44835, val loss: 0.46435, in 0.143s\n",
      "[30/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.44730, val loss: 0.46402, in 0.153s\n",
      "[31/1000] 1 tree, 31 leaves, max depth = 24, train loss: 0.44625, val loss: 0.46354, in 0.146s\n",
      "[32/1000] 1 tree, 31 leaves, max depth = 19, train loss: 0.44520, val loss: 0.46311, in 0.151s\n",
      "[33/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.44423, val loss: 0.46288, in 0.146s\n",
      "[34/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.44335, val loss: 0.46251, in 0.145s\n",
      "[35/1000] 1 tree, 31 leaves, max depth = 24, train loss: 0.44248, val loss: 0.46213, in 0.134s\n",
      "[36/1000] 1 tree, 31 leaves, max depth = 20, train loss: 0.44154, val loss: 0.46164, in 0.141s\n",
      "[37/1000] 1 tree, 31 leaves, max depth = 22, train loss: 0.44071, val loss: 0.46127, in 0.146s\n",
      "[38/1000] 1 tree, 31 leaves, max depth = 24, train loss: 0.43997, val loss: 0.46101, in 0.137s\n",
      "[39/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.43917, val loss: 0.46077, in 0.148s\n",
      "[40/1000] 1 tree, 31 leaves, max depth = 24, train loss: 0.43845, val loss: 0.46047, in 0.148s\n",
      "[41/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.43767, val loss: 0.46041, in 0.146s\n",
      "[42/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.43700, val loss: 0.46019, in 0.132s\n",
      "[43/1000] 1 tree, 31 leaves, max depth = 19, train loss: 0.43634, val loss: 0.45999, in 0.142s\n",
      "[44/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.43566, val loss: 0.45999, in 0.139s\n",
      "[45/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.43503, val loss: 0.45984, in 0.147s\n",
      "[46/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.43437, val loss: 0.45966, in 0.146s\n",
      "[47/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.43378, val loss: 0.45963, in 0.140s\n",
      "[48/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.43325, val loss: 0.45963, in 0.131s\n",
      "[49/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.43256, val loss: 0.45952, in 0.136s\n",
      "[50/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.43194, val loss: 0.45948, in 0.142s\n",
      "[51/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.43137, val loss: 0.45943, in 0.141s\n",
      "[52/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.43079, val loss: 0.45928, in 0.130s\n",
      "[53/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.43022, val loss: 0.45939, in 0.133s\n",
      "[54/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.42963, val loss: 0.45944, in 0.141s\n",
      "[55/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.42902, val loss: 0.45937, in 0.146s\n",
      "[56/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.42857, val loss: 0.45946, in 0.135s\n",
      "[57/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.42806, val loss: 0.45960, in 0.135s\n",
      "[58/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.42755, val loss: 0.45943, in 0.144s\n",
      "[59/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.42704, val loss: 0.45931, in 0.131s\n",
      "[60/1000] 1 tree, 31 leaves, max depth = 21, train loss: 0.42656, val loss: 0.45931, in 0.138s\n",
      "[61/1000] 1 tree, 31 leaves, max depth = 20, train loss: 0.42604, val loss: 0.45941, in 0.142s\n",
      "[62/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.42547, val loss: 0.45940, in 0.132s\n",
      "Fit 62 trees in 10.435 s, (1922 total leaves)\n",
      "Time spent computing histograms: 5.491s\n",
      "Time spent finding best splits:  0.663s\n",
      "Time spent applying splits:      0.121s\n",
      "Time spent predicting:           0.005s\n"
     ]
    },
    {
     "data": {
      "text/plain": "HistGradientBoostingClassifier(max_iter=1000, verbose=1)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(vec_x.toarray(), Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "vec_x_test = vectorizer.transform(Xtest)\n",
    "vec_x_test = tfidf_transformer.transform(vec_x_test)\n",
    "preds = model.predict(vec_x_test.toarray())\n",
    "\n",
    "df_ans = pd.read_csv('submission.csv')\n",
    "df_ans['label'] = preds\n",
    "df_ans.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGraderClient: Successfully Connected!\n",
      "[SERVER] MOTD: CHECK your USER_TOKEN and GRADER_URL HTTP address! I'm IoT_PART_2 @9c3fd049c87c\n",
      "ProofOfWork Challenge =>  ('CTFSGRB3dd559582f3c5bc0ed12c90f95181638', 22)\n",
      "ProofOfWork Answer Found! =>  4132791\n"
     ]
    },
    {
     "data": {
      "text/plain": "'{\"challenge\":{\"name\":\"[CSIT] IoT - Part 2\"},\"id\":\"cl2vc8wzfczr60846m48azzzf\",\"status\":\"PARTIALLY_CORRECT\",\"multiplier\":0.1287,\"submittedBy\":{\"username\":\"SSSSSSSSSSSSSSSSSSSSSDDDDDD\"},\"createdAt\":\"2022-05-07T04:00:33Z\"}'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to graders\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, r'C:\\Users\\alien\\Documents\\PyCharm-Projects\\Cyberthon 2022\\pyctfsglib.py')\n",
    "import pyctfsglib as ctfsg\n",
    "import random\n",
    "USER_TOKEN = \"NgNCyetIrzGVjgcTRnwFvjFdrJLYphEyqtVyoIgiESjpRzfQjgPiIgmKlnnyEbRb\" # You need to fill this up\n",
    "GRADER_URL = random.choice([\n",
    "  \"http://chals.cyberthon22f.ctf.sg:50201/\",\n",
    "  \"http://chals.cyberthon22f.ctf.sg:50202/\"\n",
    "])\n",
    "\n",
    "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)\n",
    "grader.submitFile('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}